
## Prepare the environment
* Install Python dependencies. We use python 3.10 and pytorch 2.0.1
```
pip install -r requirements.txt
```

## Prepare Dataset

We use Mvtec dataset

## Other Model Ckpt
Download the official checkpointï¼š

```
runwayml/stable-diffusion-v1-5
U-2-Net
```


## Training

The model not use BCM in DualAnoDiff/dual-interrelated_diff, and for every category run:
In run_mvtec_split.py, there are steps for training, inference, and generating masks.
```
cd DualAnoDiff/dual-interrelated_diff
python run_mvtec_split.py
```

The generated data will save in generated_data with struct:
```
generated_data/
        |->bottle/
        |    |->broken_small/
        |    |    |->image/
        |    |    |->mask/
        |    |    |->fg/
            ...
        ...
```
If you want to use the BCM module, you should first use U2-Net to segment the foreground mask, and then run:
```
cd DualAnoDiff/bcm-dual-interrelated_diff
python run_mvtec_split_background_control_scale.py
```
Note that you should replace /path/to/condition_dir in the code with the foreground mask directory.
And we suggest you employ BCM in the categories of bottle, pill, and toothbrush, as these can achieve better performance.
You can find the details of U2-Net on their official GitHub.

## Test the image generation 

The following code is used to measure the IS and IC-LPIPS of the generated data.
```
cd DualAnoDiff/eval
python compute-is.py
python compute-ic-lpipis.py
```


## Test the anomaly inspection performance

The following code is used to train and test a U-Net for anomaly detection and localization in MVTec.
```
cd DualAnoDiff/eval
python train-localization.py --generated_data_path $path_to_the_generated_data  --mvtec_path $path_to_mvtec --save $ckpt_dir
python test-localization.py --generated_data_path $path_to_mvtec --checkpoint_path $ckpt_dir
```

